{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC180b Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "# import torch as t  --> idk why this isn't being found, maybe memory issue\n",
    "# import skmultilearn\n",
    "\n",
    "# import biom\n",
    "# from qiime2.plugins import feature_table\n",
    "# from qiime2 import Artifact\n",
    "# from qiime2.plugins.metadata.methods import distance_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtaining file paths\n",
    "with open(\"config/data-params.json\") as fh:\n",
    "    file_paths = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_feature_table = pd.read_csv('data/raw/feature_table.csv').set_index('Unnamed: 0')\n",
    "raw_feature_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_metadata = pd.read_csv('data/raw/11666_metadata.txt', sep='\\t', index_col=0)\n",
    "raw_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset metadata based on existing samples in feature table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_metadata = raw_metadata.loc[raw_feature_table.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep relevant diseases (classes) and features in metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases_cols = {\n",
    "    'abdominal_obesity_ncep_v2': 'obesity',\n",
    "    'diabetes2_v2': 'diabetes',\n",
    "    'dyslipidemia_v2': 'dyslipidemia',\n",
    "    'hypertension2_v2': 'hypertension',\n",
    "    'ckd_v2': 'ckd',\n",
    "    'precvd_v2': 'precvd',\n",
    "    'elevated_bp_selfmeds_v2': 'elevated_bp',\n",
    "}\n",
    "           \n",
    "other_feature_cols = {\n",
    "    'age_v2': 'age',\n",
    "    'center': 'center',\n",
    "    'gender': 'gender',\n",
    "    'host_body_mass_index': 'BMI'\n",
    "}\n",
    "\n",
    "subset_cols = diseases_cols | other_feature_cols\n",
    "\n",
    "metadata = raw_metadata[subset_cols.keys()].rename(columns=subset_cols)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = metadata[metadata.isna().any(axis=1)].index\n",
    "na_rows = metadata[(metadata == 'not applicable').all(axis=1)].index\n",
    "np_rows = metadata[(metadata == 'not provided').all(axis=1)].index\n",
    "drop_rows = np.concatenate((nan_rows, na_rows, np_rows))\n",
    "\n",
    "filtered_metadata = metadata.drop(drop_rows)\n",
    "filtered_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map values in each class to binary. 1 in a column means a sample contains the corresponding disease, and 0 means it does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disease_metadata = filtered_metadata[diseases_cols.values()].astype(int)\n",
    "\n",
    "for col in disease_metadata:\n",
    "    print(col, disease_metadata[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DISEASE VALUE MAPS\n",
    "\n",
    "diabetes_binary = {1: 0,\n",
    "                   2: 0,\n",
    "                   3: 1}\n",
    "ckd_binary = {1: 0,\n",
    "             2: 1,\n",
    "             3: 1,\n",
    "             4: 1,\n",
    "             5: 1}\n",
    "\n",
    "disease_metadata['diabetes'] = disease_metadata['diabetes'].map(diabetes_binary)\n",
    "disease_metadata['ckd'] = disease_metadata['ckd'].map(ckd_binary)\n",
    "\n",
    "diseases = disease_metadata\n",
    "diseases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Feature Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset feature table based on existing samples in cleaned metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_feature_table = raw_feature_table.loc[diseases.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_feature_table.sum(axis=0).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove noise by filtering out sequences that have fewer than 100,000 reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 100_000\n",
    "filtered_cols = raw_feature_table.sum(axis=0) > threshold\n",
    "features = raw_feature_table.T.loc[filtered_cols].T\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df = diseases.copy()\n",
    "eda_df['total_diseases'] = eda_df.sum(axis=1) #how many diseases each sample has\n",
    "eda_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DISEASE PER SAMPLE COUNTS\n",
    "\n",
    "multiple_disease_counts = eda_df['total_diseases'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.set_title('Disease per Sample Counts')\n",
    "ax.set_ylabel('Number of Samples')\n",
    "ax.set_xlabel('Number of Diseases')\n",
    "ax.bar(multiple_disease_counts.index, multiple_disease_counts.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SIZE OF EACH CLASS (DISEASE)\n",
    "\n",
    "disease_counts = eda_df.drop(columns='total_diseases').sum(axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.set_title('Samples per Disease')\n",
    "ax.set_ylabel('Number of Samples')\n",
    "ax.set_xlabel('Diseases')\n",
    "ax.bar(disease_counts.index, disease_counts.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In case we use pytorch\n",
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(t.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(t.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(t.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_gbc_model():\n",
    "    loss='exponential'\n",
    "    learning_rate=0.1 \n",
    "    n_estimators=150 \n",
    "    max_depth=3\n",
    "    random_state=0\n",
    "    \n",
    "    clf = GradientBoostingClassifier(loss=loss, \n",
    "                                     learning_rate=learning_rate, \n",
    "                                     n_estimators=n_estimators, \n",
    "                                     max_depth=max_depth, \n",
    "                                     random_state=random_state)\n",
    "    \n",
    "    return clf\n",
    "\n",
    "\n",
    "\n",
    "def init_skf():\n",
    "    \"\"\"Function for initializing the StratifiedKFold cross-validator\n",
    "\n",
    "    Args:\n",
    "        n_splits (int): Number of splits to seperate data\n",
    "        shuffle (boolean): Wheter to shuffle data\n",
    "        skf_random_state (int): random_state\n",
    "\n",
    "    Returns:\n",
    "        StratifiedKFold: Initialized StratifiedKFold cross-validator\n",
    "    \"\"\"\n",
    "    n_splits=10\n",
    "    random_state=0\n",
    "    shuffle=True\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits,shuffle=shuffle, random_state=random_state)\n",
    "    \n",
    "    return skf\n",
    "\n",
    "#Maybe build tuning pipeline later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "metrics = {}\n",
    "\n",
    "X = features\n",
    "for i, disease in enumerate(diseases, start=1):\n",
    "    skf = init_skf()\n",
    "    clf = init_gbc_model()\n",
    "    \n",
    "    y = diseases[disease]\n",
    "    \n",
    "    best_acc = float('-inf')\n",
    "    \n",
    "    print('Training {} Classifier...'.format(disease))\n",
    "    i=1\n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "        \n",
    "        train_X, train_y = X.iloc[train_index], y.iloc[train_index]\n",
    "        val_X, val_y = X.iloc[val_index], y.iloc[val_index]\n",
    "\n",
    "        clf.fit(train_X, train_y)\n",
    "        \n",
    "        preds = clf.predict(val_X)\n",
    "#         preds = clf.predict_proba(val_X)[:,1] #predict probability of positive class predict\n",
    "        \n",
    "        acc = np.mean(preds==val_y)\n",
    "        \n",
    "        if acc >= best_acc:\n",
    "            best_model = clf\n",
    "            best_acc = acc\n",
    "            \n",
    "        print('Finished training split {}'.format(i))\n",
    "        i+=1\n",
    "        \n",
    "    classifiers[disease] = best_model\n",
    "    metrics[disease] = best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapted Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f3eb80ecefa8a2bb623a916cf91dd59a834c9ebe3cfa6e57c9edbb4634331c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
